{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Zach\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "#\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "#\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "#shortword.sub('', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stopWords(object):\n",
    "    \"\"\"  \"\"\"\n",
    "    def __init__(self):\n",
    "        titles = set([word.title() for word in stopwords.words('english')])\n",
    "        uppers = set([word.upper() for word in stopwords.words('english')])\n",
    "        self.stopword_set = set(stopwords.words('english')) | titles | uppers\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\" \"\"\"\n",
    "        text = text.split(' ')\n",
    "        return ' '.join([word for word in text if word not in self.stopword_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document(object):\n",
    "    \"\"\"  \"\"\"\n",
    "    def __init__(self, source, source_type='html'):\n",
    "        self.source = source\n",
    "        self.source_type = source_type\n",
    "        \n",
    "        # Placeholders\n",
    "        self.raw_doc = None\n",
    "        self.paragraphs = None\n",
    "        self.processed_paragraphs = None\n",
    "        self.counters = None\n",
    "        self.wordcount = None\n",
    "        \n",
    "        # Static elements  # TODO move to module\n",
    "        self.banned_strs = '()[]{}@#$%^&*+=,`\\\"\\'\\\\1234567890'\n",
    "        self.stopwords = stopWords()\n",
    "        \n",
    "        if source_type == 'html':\n",
    "            \"\"\" Source is page url \"\"\"\n",
    "            self.collect_paragraphs()\n",
    "            self.process_paragraphs()\n",
    "        \n",
    "    def collect_paragraphs(self):\n",
    "        \"\"\" \"\"\"\n",
    "        with urllib.request.urlopen(self.source) as page:\n",
    "            self.raw_doc = BeautifulSoup(page, \"html.parser\")\n",
    "        \n",
    "        # Get all paragraphs and add text to document\n",
    "        paragraphs = self.raw_doc.find_all('p')\n",
    "        for pind, paragraph in enumerate(paragraphs):\n",
    "            paragraphs[pind] = paragraph.text\n",
    "            \n",
    "        # Remove empty paragraphs\n",
    "        paragraphs = list(filter(None, paragraphs)) # fastest\n",
    "        \n",
    "        self.paragraphs = paragraphs\n",
    "        self.processed_paragraphs = [None]*len(self.paragraphs)\n",
    "        self.counters = [None]*len(self.paragraphs)\n",
    "        \n",
    "    def process_paragraphs(self):\n",
    "        \"\"\" \"\"\"\n",
    "        for pind, paragraph in enumerate(self.paragraphs):\n",
    "            int_par = paragraph.translate({ord(c): None for c in self.banned_strs})\n",
    "            self.processed_paragraphs[pind] = \\\n",
    "                self.stopwords.remove_stopwords(int_par)\n",
    "                \n",
    "    def create_counters(self):\n",
    "        \"\"\" \"\"\"\n",
    "        for ii, _ in enumerate(self.counters):\n",
    "            poi = self.processed_paragraphs[ii]\n",
    "            no_punc = poi.translate({ord(c): None for c in '.?!'})\n",
    "            lower = [word.lower() for word in no_punc.split(' ')]\n",
    "            # Remove empty words\n",
    "            words = list(filter(None, lower)) # fastest\n",
    "            \n",
    "            self.counters[ii] = Counter(words)\n",
    "            \n",
    "        self.wordcount = sum(self.counters, Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url = 'https://en.wikipedia.org/wiki/Semantic_Web'\n",
    "page_type = 'html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document(page_url, source_type=page_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Semantic Web extension World Wide Web standards World Wide Web Consortium WC. standards promote common data formats exchange protocols Web fundamentally Resource Description Framework RDF. According WC Semantic Web provides common framework allows data shared reused across application enterprise community boundaries. Semantic Web therefore regarded integrator across different content information applications systems.',\n",
       " 'term coined Tim Berners-Lee web data data web processed machines—that one much meaning machine-readable. critics questioned feasibility proponents argue applications industry biology human sciences research already proven validity original concept.',\n",
       " 'Berners-Lee originally expressed vision Semantic Web follows:',\n",
       " 'dream Web computers become capable analyzing data Web\\xa0– content links transactions people computers. Semantic Web makes possible yet emerge day-to-day mechanisms trade bureaucracy daily lives handled machines talking machines. intelligent agents people touted ages finally materialize.',\n",
       " ' Scientific American article Berners-Lee Hendler Lassila described expected evolution existing Web Semantic Web.  Berners-Lee colleagues stated that: simple idea…remains largely unrealized.  four million Web domains contained Semantic Web markup.',\n",
       " 'following example text Paul Schuster born Dresden Website annotated connecting person place birth. following HTML-fragment shows small graph described RDFa-syntax using schema.org vocabulary Wikidata ID:',\n",
       " 'example defines following five triples shown Turtle Syntax. triple represents one edge resulting graph: first element triple subject name node edge starts second element predicate type edge last third element object either name node edge ends literal value e.g. text number etc..',\n",
       " 'triples result graph shown given figure.',\n",
       " 'One advantages using Uniform Resource Identifier URIs dereferenced using HTTP protocol. According so-called Linked Open Data principles dereferenced URI result document offers data given URI. example URIs edges nodes e.g. http://schema.org/Person http://schema.org/birthPlace http://www.wikidata.org/entity/Q dereferenced result RDF graphs describing URI e.g. Dresden city Germany person sense URI fictional.',\n",
       " 'second graph shows previous example enriched triples documents result dereferencing http://schema.org/Person green edge http://www.wikidata.org/entity/Q blue edges.',\n",
       " 'Additionally edges given involved documents explicitly edges automatically inferred: triple',\n",
       " 'original RDFa fragment triple',\n",
       " 'document http://schema.org/Person green edge Figure allow infer following triple given OWL semantics red dashed line second Figure:',\n",
       " 'concept Semantic Network Model formed early cognitive scientist Allan M. Collins linguist M. Ross Quillian psychologist Elizabeth F. Loftus form represent semantically structured knowledge. applied context modern internet extends network hyperlinked human-readable web pages inserting machine-readable metadata pages related other. enables automated agents access Web intelligently perform tasks behalf users. term Semantic Web coined Tim Berners-Lee inventor World Wide Web director World Wide Web Consortium WC oversees development proposed Semantic Web standards. defines Semantic Web web data processed directly indirectly machines.',\n",
       " 'Many technologies proposed WC already existed positioned WC umbrella. used various contexts particularly dealing information encompasses limited defined domain sharing data common necessity scientific research data exchange among businesses. addition technologies similar goals emerged microformats.',\n",
       " 'Many files typical computer also loosely divided human readable documents machine readable data. Documents like mail messages reports brochures read humans. Data calendars addressbooks playlists spreadsheets presented using application program lets viewed searched combined.',\n",
       " 'Currently World Wide Web based mainly documents written Hypertext Markup Language HTML markup convention used coding body text interspersed multimedia objects images interactive forms. Metadata tags provide method computers categorise content web pages example:',\n",
       " 'HTML tool render perhaps web browser software perhaps another user agent one create present page lists items sale. HTML catalog page make simple document-level assertions documents title Widget Superstore capability within HTML assert unambiguously example item number X Acme Gizmo retail price € consumer product. Rather HTML say span text X something positioned near Acme Gizmo € etc. way say catalog even establish Acme Gizmo kind title € price. also way express pieces information bound together describing discrete item distinct items perhaps listed page.',\n",
       " 'Semantic HTML refers traditional HTML practice markup following intention rather specifying layout details directly. example use <em> denoting emphasis rather <i> specifies italics. Layout details left browser combination Cascading Style Sheets. practice falls short specifying semantics objects items sale prices.',\n",
       " 'Microformats extend HTML syntax create machine-readable semantic markup objects including people organisations events products. Similar initiatives include RDFa Microdata Schema.org.',\n",
       " 'Semantic Web takes solution further. involves publishing languages specifically designed data: Resource Description Framework RDF Web Ontology Language OWL Extensible Markup Language XML. HTML describes documents links them. RDF OWL XML contrast describe arbitrary things people meetings airplane parts.',\n",
       " 'technologies combined order provide descriptions supplement replace content Web documents. Thus content may manifest descriptive data stored Web-accessible databases markup within documents particularly Extensible HTML XHTML interspersed XML often purely XML layout rendering cues stored separately. machine-readable descriptions enable content managers add meaning content i.e. describe structure knowledge content. way machine process knowledge instead text using processes similar human deductive reasoning inference thereby obtaining meaningful results helping computers perform automated information gathering research.',\n",
       " 'example tag would used non-semantic web page:',\n",
       " 'Encoding similar information semantic web page might look like this:',\n",
       " 'Tim Berners-Lee calls resulting network Linked Data Giant Global Graph contrast HTML-based World Wide Web. Berners-Lee posits past document sharing future data sharing. answer question provides three points instruction. One URL point data. Two anyone accessing URL get data back. Three relationships data point additional URLs data.',\n",
       " 'Tim Berners-Lee described semantic web component Web ..',\n",
       " 'People keep asking Web . is. think maybe youve got overlay scalable vector graphics\\xa0– everything rippling folding looking misty\\xa0– Web . access semantic Web integrated across huge space data youll access unbelievable data resource …',\n",
       " 'Semantic Web sometimes used synonym Web . though definition term varies. Web . started emerge movement away centralisation services like search social media chat applications dependent single organisation function.',\n",
       " 'challenges Semantic Web include vastness vagueness uncertainty inconsistency deceit. Automated reasoning systems deal issues order deliver promise Semantic Web.',\n",
       " 'list challenges illustrative rather exhaustive focuses challenges unifying logic proof layers Semantic Web. World Wide Web Consortium WC Incubator Group Uncertainty Reasoning World Wide Web URW-XG final report lumps problems together single heading uncertainty. Many techniques mentioned require extensions Web Ontology Language OWL example annotate conditional probabilities. area active research.',\n",
       " 'Standardization Semantic Web context Web . care WC.',\n",
       " 'term Semantic Web often used specifically refer formats technologies enable it. collection structuring recovery linked data enabled technologies provide formal description concepts terms relationships within given knowledge domain. technologies specified WC standards include:',\n",
       " 'Semantic Web Stack illustrates architecture Semantic Web. functions relationships components summarized follows:',\n",
       " 'Well-established standards:',\n",
       " 'yet fully realized:',\n",
       " 'intent enhance usability usefulness Web interconnected resources creating Semantic Web Services as:',\n",
       " 'services could useful public search engines could used knowledge management within organization. Business applications include:',\n",
       " 'corporation closed group users management able enforce company guidelines like adoption specific ontologies use semantic annotation. Compared public Semantic Web lesser requirements scalability information circulating within company trusted general; privacy less issue outside handling customer data.',\n",
       " 'Critics question basic feasibility complete even partial fulfillment Semantic Web pointing difficulties setting lack general-purpose usefulness prevents required effort invested.  paper Marshall Shipman point cognitive overhead inherent formalizing knowledge compared authoring traditional web hypertext:',\n",
       " 'learning basics HTML relatively straightforward learning knowledge representation language tool requires author learn representations methods abstraction effect reasoning. example understanding class-instance relationship superclass-subclass relationship understanding one concept “type of” another concept. … abstractions taught computer scientists generally knowledge engineers specifically match similar natural language meaning type something. Effective use formal representation requires author become skilled knowledge engineer addition skills required domain. … one learned formal representation language still often much effort express ideas representation less formal representation …. Indeed form programming based declaration semantic data requires understanding reasoning algorithms interpret authored structures.',\n",
       " 'According Marshall Shipman tacit changing nature much knowledge adds knowledge engineering problem limits Semantic Webs applicability specific domains. issue point domain- organisation-specific ways express knowledge must solved community agreement rather technical means. turns specialized communities organizations intra-company projects tended adopt semantic web technologies greater peripheral less-specialized communities. practical constraints toward adoption appeared less challenging domain scope limited general public World-Wide Web.',\n",
       " 'Finally Marshall Shipman see pragmatic problems idea Knowledge Navigator-style intelligent agents working largely manually curated Semantic Web:',\n",
       " 'situations user needs known distributed information resources well described approach highly effective; situations foreseen bring together unanticipated array information resources Google approach robust. Furthermore Semantic Web relies inference chains brittle; missing element chain results failure perform desired action human supply missing pieces Google-like approach. … cost-benefit tradeoffs work favor specially-created Semantic Web metadata directed weaving together sensible well-structured domain-specific information resources; close attention user/customer needs drive federations successful.',\n",
       " 'Cory Doctorows critique metacrap perspective human behavior personal preferences. example people may include spurious metadata Web pages attempt mislead Semantic Web engines naively assume metadatas veracity. phenomenon well-known metatags fooled Altavista ranking algorithm elevating ranking certain Web pages: Google indexing engine specifically looks attempts manipulation. Peter Gärdenfors Timo Honkela point logic-based semantic web technologies cover fraction relevant phenomena related semantics.',\n",
       " 'Enthusiasm semantic web could tempered concerns regarding censorship privacy. instance text-analyzing techniques easily bypassed using words metaphors instance using images place words. advanced implementation semantic web would make much easier governments control viewing creation online information information would much easier automated content-blocking machine understand. addition issue also raised use FOAF files geolocation meta-data would little anonymity associated authorship articles things personal blog. concerns addressed Policy Aware Web project active research development topic.',\n",
       " 'Another criticism semantic web would much time-consuming create publish content would need two formats one piece data: one human viewing one machines. However many web applications development addressing issue creating machine-readable format upon publishing data request machine data. development microformats one reaction kind criticism. Another argument defense feasibility semantic web likely falling price human intelligence tasks digital labor markets Amazons Mechanical Turk.citation needed',\n",
       " 'Specifications eRDF RDFa allow arbitrary RDF data embedded HTML pages. GRDDL Gleaning Resource Descriptions Dialects Language mechanism allows existing material including microformats automatically interpreted RDF publishers need use single format HTML.',\n",
       " 'first research group explicitly focusing Corporate Semantic Web ACACIA team INRIA-Sophia-Antipolis founded . Results work include RDFS based Corese search engine application semantic web technology realm E-learning.',\n",
       " 'Since  Corporate Semantic Web research group located Free University Berlin focuses building blocks: Corporate Semantic Search Corporate Semantic Collaboration Corporate Ontology Engineering.',\n",
       " 'Ontology engineering research includes question involve non-expert users creating ontologies semantically annotated content extracting explicit knowledge interaction users within enterprises.',\n",
       " 'Tim OReilly coined term Web . proposed long-term vision Semantic Web web data sophisticated applications manipulate data web. data web transforms Web distributed file system distributed database system.',\n",
       " 'See also: Logic machines fiction List fictional computers']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.processed_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document.create_counters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('web', 79),\n",
       " ('semantic', 47),\n",
       " ('data', 30),\n",
       " ('knowledge', 14),\n",
       " ('html', 13),\n",
       " ('information', 11),\n",
       " ('one', 11),\n",
       " ('content', 10),\n",
       " ('example', 10),\n",
       " ('documents', 9),\n",
       " ('world', 8),\n",
       " ('wide', 8),\n",
       " ('wc', 8),\n",
       " ('berners-lee', 8),\n",
       " ('research', 8)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.wordcount.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'semantic': 47,\n",
       " 'web': 79,\n",
       " 'world': 8,\n",
       " 'wide': 8,\n",
       " 'standards': 4,\n",
       " 'consortium': 3,\n",
       " 'wc': 8,\n",
       " 'common': 3,\n",
       " 'data': 30,\n",
       " 'formats': 3,\n",
       " 'resource': 5,\n",
       " 'description': 3,\n",
       " 'framework': 3,\n",
       " 'rdf': 6,\n",
       " 'according': 3,\n",
       " 'across': 3,\n",
       " 'application': 3,\n",
       " 'content': 10,\n",
       " 'information': 11,\n",
       " 'applications': 6,\n",
       " 'term': 5,\n",
       " 'coined': 3,\n",
       " 'tim': 5,\n",
       " 'berners-lee': 8,\n",
       " 'one': 11,\n",
       " 'much': 6,\n",
       " 'meaning': 3,\n",
       " 'machine-readable': 5,\n",
       " 'feasibility': 3,\n",
       " 'human': 7,\n",
       " 'research': 8,\n",
       " 'concept': 4,\n",
       " 'computers': 5,\n",
       " 'people': 6,\n",
       " 'machines': 5,\n",
       " 'agents': 3,\n",
       " 'described': 4,\n",
       " 'markup': 7,\n",
       " 'following': 5,\n",
       " 'example': 10,\n",
       " 'text': 5,\n",
       " 'graph': 4,\n",
       " 'using': 7,\n",
       " 'triples': 3,\n",
       " 'triple': 5,\n",
       " 'edge': 6,\n",
       " 'element': 4,\n",
       " 'second': 3,\n",
       " 'eg': 3,\n",
       " 'result': 4,\n",
       " 'given': 5,\n",
       " 'dereferenced': 3,\n",
       " 'linked': 3,\n",
       " 'uri': 4,\n",
       " 'document': 3,\n",
       " 'edges': 4,\n",
       " 'http://schemaorg/person': 3,\n",
       " 'documents': 9,\n",
       " 'rdfa': 3,\n",
       " 'owl': 4,\n",
       " 'semantics': 3,\n",
       " 'network': 3,\n",
       " 'knowledge': 14,\n",
       " 'pages': 5,\n",
       " 'metadata': 4,\n",
       " 'automated': 4,\n",
       " 'access': 3,\n",
       " 'perform': 3,\n",
       " 'users': 4,\n",
       " 'development': 4,\n",
       " 'proposed': 3,\n",
       " 'many': 4,\n",
       " 'technologies': 8,\n",
       " 'used': 6,\n",
       " 'domain': 4,\n",
       " 'sharing': 3,\n",
       " 'addition': 3,\n",
       " 'similar': 5,\n",
       " 'microformats': 4,\n",
       " 'also': 3,\n",
       " 'machine': 4,\n",
       " 'like': 4,\n",
       " 'based': 3,\n",
       " 'language': 8,\n",
       " 'html': 13,\n",
       " 'objects': 3,\n",
       " 'provide': 3,\n",
       " 'perhaps': 3,\n",
       " 'another': 4,\n",
       " 'create': 3,\n",
       " 'page': 4,\n",
       " 'items': 3,\n",
       " 'within': 6,\n",
       " 'acme': 3,\n",
       " 'gizmo': 3,\n",
       " 'price': 3,\n",
       " '€': 3,\n",
       " 'rather': 5,\n",
       " 'way': 3,\n",
       " 'express': 3,\n",
       " 'together': 4,\n",
       " 'layout': 3,\n",
       " 'use': 5,\n",
       " 'include': 4,\n",
       " 'specifically': 4,\n",
       " 'ontology': 4,\n",
       " 'xml': 4,\n",
       " 'descriptions': 3,\n",
       " 'often': 3,\n",
       " 'reasoning': 5,\n",
       " 'results': 3,\n",
       " 'would': 6,\n",
       " 'question': 3,\n",
       " 'point': 5,\n",
       " 'relationships': 3,\n",
       " '…': 5,\n",
       " 'services': 3,\n",
       " 'search': 4,\n",
       " 'single': 3,\n",
       " 'challenges': 3,\n",
       " 'uncertainty': 3,\n",
       " 'group': 4,\n",
       " 'formal': 4,\n",
       " 'resources': 3,\n",
       " 'creating': 3,\n",
       " 'could': 3,\n",
       " 'public': 3,\n",
       " 'less': 3,\n",
       " 'issue': 4,\n",
       " 'marshall': 3,\n",
       " 'shipman': 3,\n",
       " 'representation': 5,\n",
       " 'requires': 3,\n",
       " 'understanding': 3,\n",
       " 'engineering': 3,\n",
       " 'distributed': 3,\n",
       " 'approach': 3,\n",
       " 'corporate': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have important words, so we can trim words that only appear x number of times in document of length y \n",
    "#  for now this is static at 2 instances\n",
    "document_length = sum([len(paragraph) for paragraph in document.paragraphs])\n",
    "print(document_length)\n",
    "wordcount_dict = dict(document.wordcount)\n",
    "for key in list(wordcount_dict.keys()):\n",
    "    num_instances = wordcount_dict[key]\n",
    "    if num_instances < 3:\n",
    "        wordcount_dict.pop(key)\n",
    "        \n",
    "wordcount_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to create a n-length phrase list so phrases like \"Semantic Web\"\n",
    "#   and \"World Wide Web\" are extracted and treated separately from \n",
    "#   words like \"web\" by itself\n",
    "\n",
    "# I think the second can be done early on by tracking what words are removed. \n",
    "# If a stopword separates several words with higher value, a phrase is generated.\n",
    "# For example (Note sw=stopword, vw=valueword):\n",
    "#    \"The Semantic Web is an extension of the World Wide Web\"\n",
    "#      sw   vw      vw sw sw    vw     sw  sw   sw   sw   sw\n",
    "# Extracted phrases:\n",
    "#    - Semantic Web\n",
    "#    - extension (removed as singular word)\n",
    "#    - World Wide Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (winpy36)",
   "language": "python",
   "name": "winpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
